# AION-R Environment Configuration Example
# Copy this file to .env and fill in your API keys

# ============================================================================
# LLM PROVIDERS (Multi-Provider with Automatic Fallback)
# ============================================================================
# At least ONE provider is recommended for full AI capabilities

# Groq API (RECOMMENDED - Fastest inference, free tier available)
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=gsk_your_groq_api_key_here

# OpenAI API (High quality, paid service)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your_openai_api_key_here

# Hugging Face Inference API (Free tier available)
# Get your token at: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=hf_your_huggingface_token_here

# GitHub Models (FREE - Requires GitHub account)
# Use your GitHub Personal Access Token
# Create at: https://github.com/settings/tokens
GITHUB_TOKEN=ghp_your_github_token_here

# Cloudflare AI Workers (Serverless, pay-as-you-go)
# Get credentials at: https://dash.cloudflare.com/
CLOUDFLARE_API_KEY=your_cloudflare_api_key_here
CLOUDFLARE_ACCOUNT_ID=your_cloudflare_account_id_here

# ============================================================================
# DATABASE
# ============================================================================

# PostgreSQL connection
DATABASE_URL=postgresql://aion_user:aion_pass@localhost:5432/aion_r

# Redis connection
REDIS_URL=redis://:aion_redis_pass@localhost:6379

# ============================================================================
# WEB SERVER
# ============================================================================

# Server configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8080

# JWT secret for authentication (generate with: openssl rand -hex 32)
JWT_SECRET=your_256_bit_secret_key_here_change_this_in_production

# Session configuration
SESSION_TIMEOUT_HOURS=24
COOKIE_SECURE=false  # Set to true in production with HTTPS

# ============================================================================
# SECURITY
# ============================================================================

# Encryption key for secrets (generate with: openssl rand -hex 32)
ENCRYPTION_KEY=your_encryption_key_here_change_this_in_production

# CORS allowed origins (comma-separated)
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# Rate limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# ============================================================================
# LOGGING & MONITORING
# ============================================================================

# Logging level (trace, debug, info, warn, error)
RUST_LOG=info,aion_ai_engine=debug,aion_web_api=info

# Enable telemetry
ENABLE_TELEMETRY=true

# Prometheus metrics endpoint
METRICS_ENABLED=true
METRICS_PORT=9090

# ============================================================================
# AI ENGINE CONFIGURATION
# ============================================================================

# Model cache directory
MODEL_CACHE_DIR=./models

# Maximum memory for AI operations (in GB)
MAX_AI_MEMORY_GB=8

# Maximum concurrent inferences
MAX_CONCURRENT_INFERENCES=10

# Autocorrection configuration
MAX_AUTOCORRECTION_ITERATIONS=5
MIN_IMPROVEMENT_THRESHOLD_PERCENT=5.0

# ============================================================================
# STORAGE
# ============================================================================

# MinIO/S3 configuration
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=aion_access_key
MINIO_SECRET_KEY=aion_secret_key
MINIO_BUCKET=aion-projects

# ============================================================================
# MESSAGE QUEUE
# ============================================================================

# RabbitMQ configuration
RABBITMQ_URL=amqp://aion_user:aion_pass@localhost:5672/aion_vhost

# ============================================================================
# THIRD-PARTY INTEGRATIONS
# ============================================================================

# GitHub integration (for repository operations)
GITHUB_APP_ID=
GITHUB_APP_PRIVATE_KEY_PATH=

# Docker registry (for deployments)
DOCKER_REGISTRY_URL=
DOCKER_REGISTRY_USERNAME=
DOCKER_REGISTRY_PASSWORD=

# Stripe (for payments - optional)
STRIPE_SECRET_KEY=
STRIPE_PUBLISHABLE_KEY=
STRIPE_WEBHOOK_SECRET=

# ============================================================================
# DEVELOPMENT
# ============================================================================

# Environment mode
ENVIRONMENT=development  # development, staging, production

# Enable debug features
DEBUG_MODE=true

# Hot reload
WATCH_MODE=true

# ============================================================================
# NOTES
# ============================================================================
#
# LLM Provider Priority (automatic fallback):
# 1. Groq (fastest)
# 2. OpenAI (most capable)
# 3. GitHub Models (free)
# 4. Hugging Face (open models)
# 5. Cloudflare AI (serverless)
#
# The system will try providers in order until one succeeds.
# Configure at least one for full functionality.
#
# Security Best Practices:
# - Never commit .env file to version control
# - Use strong, randomly generated secrets in production
# - Enable HTTPS/TLS in production (set COOKIE_SECURE=true)
# - Rotate secrets regularly
# - Use environment-specific .env files (.env.production, .env.staging)
#
