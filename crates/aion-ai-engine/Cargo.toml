[package]
name = "aion-ai-engine"
version = "1.0.0"
edition = "2021"
description = "AI/ML engine for AION-R"

[dependencies]
aion-core = { path = "../aion-core" }

# AI/ML frameworks
candle-core = "0.3"
candle-nn = "0.3"
candle-transformers = "0.3"
torch = { version = "0.13", optional = true }
tensorflow = { version = "0.21", optional = true }
ort = { version = "1.16", features = ["copy-dylibs"], optional = true }  # ONNX Runtime

# Machine Learning utilities
nalgebra = "0.32"
ndarray = "0.15"
linfa = "0.7"
linfa-clustering = "0.7"
linfa-linear = "0.7"
linfa-trees = "0.7"
smartcore = "0.3"

# Text processing and NLP
tokenizers = "0.15"
hf-hub = "0.3"
regex = "1.10"
unicode-normalization = "0.1"

# Image processing
image = "0.24"
imageproc = "0.23"

# Audio processing
rodio = { version = "0.17", optional = true }
whisper-rs = { version = "0.10", optional = true }

# Async and concurrent processing
tokio = { version = "1.0", features = ["full"] }
futures = "0.3"
rayon = "1.8"
dashmap = "5.5"
arc-swap = "1.6"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
bincode = "1.3"

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Logging and metrics
tracing = "0.1"
metrics = "0.22"

# Memory management
bytes = "1.5"

# Configuration
config = "0.14"

# Time and UUIDs
chrono = { version = "0.4", features = ["serde"] }
uuid = { version = "1.0", features = ["v4", "serde"] }

# HTTP client for model downloads
reqwest = { version = "0.11", features = ["json", "stream"] }

# Compression
flate2 = "1.0"
tar = "0.4"

[features]
default = ["candle", "nlp", "vision"]
candle = ["candle-core", "candle-nn", "candle-transformers"]
torch = ["dep:torch"]
tensorflow = ["dep:tensorflow"]
onnx = ["dep:ort"]
nlp = ["tokenizers", "hf-hub"]
vision = ["image", "imageproc"]
audio = ["dep:rodio", "dep:whisper-rs"]
training = ["linfa", "smartcore"]